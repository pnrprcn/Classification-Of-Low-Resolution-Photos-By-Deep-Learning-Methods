from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.utils import np_utils
from tensorflow.python.keras import backend
from keras.applications.resnet50 import ResNet50
from keras.applications.vgg19 import VGG19 
from keras.optimizers import SGD
from keras.models import Model
import numpy as np
import matplotlib.pyplot as plt
import os
from PIL import Image
from numpy import *

from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.metrics import  confusion_matrix
import itertools
import tensorflow as tf



def plot_confusion_matrix(cm,classes,normalize=False,tilte='Confusion Matrix',cmap=plt.cm.Blues):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(tilte)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks,classes,rotation=45)
    plt.yticks(tick_marks,classes)

    if(normalize):
        cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]
        print("Normalized confusion matrix")
    else:
        print("Confusion matrix, without normalization")
    print(cm)

    thresh = cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]),  range(cm.shape[1])):
        plt.text(j,i,cm[i,j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    print("Confusion Matrix sonuclandi")
print('16 satir')

img_rows, img_cols = 35, 35

img_channels = 1

path1 = '/content/drive/My Drive/2classifiedbirlestirilmisresized'  #dataset file
#path1 = 'trainData'
imlist = os.listdir(path1)
num_samples = size(imlist)

print('getting images after num of samples.')

immatrix = array([array(Image.open(path1 + '/' + im2)).flatten()
                  for im2 in imlist], 'f')

label = np.ones((num_samples,), dtype=int)

#label[0:525] = 0
#label[525:1050] = 1
#label[1050:1575] = 2
#label[1575:2100] = 3
#label[2100:2625] = 4

label[0:381] = 0
label[381:906] = 1


data, Label = shuffle(immatrix, label, random_state=2)
train_data = [data, Label]
print('data shuffled')
batch_size = 64
nb_classes = 2 #how many classes is to classified.
nb_epoch = 500 #epoch
nb_filters = 32
nb_pool = 2
nb_conv = 3


(X, y) = (train_data[0], train_data[1])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)

X_train = X_train.reshape(X_train.shape[0],img_rows, img_cols,1)
X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

X_train /= 255
X_test /= 255

print('X_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')
print(X_test.shape[0], 'test samples')

Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)
print('creating model')
model = Sequential()
print('78 satir. Sequential model initilized')
model.add(Convolution2D(32, (3, 3),
                        border_mode='valid',
                        input_shape=(img_rows, img_cols,1), data_format='channels_last'))
convout1 = Activation('relu')
model.add(convout1)
print('conv1 added')
model.add(Convolution2D(32, (3, 3)))
convout2 = Activation('relu')
model.add(convout2)
print('conv2 added')
model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))
model.add(Dropout(0.5))

model.add(Convolution2D(32, (3, 3)))
convout2 = Activation('relu')
model.add(convout2)
model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))
model.add(Dropout(0.5))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(nb_classes))
model.add(Activation('softmax'))
print('93 satir. compile oncesi')
model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])
print('92 satir model hazir')
hist = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,
                  verbose=1, validation_split=0.2)
print('98 satir fit done')
model.save('my_model_2_2class.h5')
print('98 satir. Model save my_model_2_2class.h5')
model_json = model.to_json()
with open("model2class.json", "w") as json_file:
    json_file.write(model_json)
    print('98 satir. json_file.write model.json')
model.save_weights("model2class.h5")
print('98 satir. Model save_weights model.h5')
score = model.evaluate(X_test, Y_test, verbose=0)
rounded_predictions = model.predict_classes(X_test, batch_size=10, verbose=0)
rounded_labels = np.argmax(Y_test,axis=1)
cm = confusion_matrix(rounded_labels,rounded_predictions)
#cm_plot_labels= ['First','Second','Third','Fourth','Fifth']
cm_plot_labels= ['First','Second']
plot_confusion_matrix(cm,cm_plot_labels,tilte='Confusion Matrix')
print('98 satir. Model evaluate test data')
print('Test score:', score[0])
print('Test accuracy:', score[1])
